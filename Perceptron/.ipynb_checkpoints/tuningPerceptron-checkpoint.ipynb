{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c4744f-f31e-483e-bdb9-830419ba8be0",
   "metadata": {},
   "source": [
    "#### Testing Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f9c78-793e-4a73-bafc-f8b5c7476eae",
   "metadata": {},
   "source": [
    "#### Initialising Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d4502-9572-485e-b8d3-b154db96d311",
   "metadata": {},
   "source": [
    "First we load in the pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19ebd43-92ec-45ed-b119-24f33b795941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import load_iris\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from random import randint\n",
    "\n",
    "\n",
    "# Read in csv\n",
    "data = pd.read_csv('data/diabetic_data_formatted.csv')\n",
    "\n",
    "\n",
    "# Remove the columns that have ~0.5 or more '?'\n",
    "data.drop(['weight', 'medical_specialty'], axis=1, inplace=True)\n",
    "\n",
    "# Replace <30 or >30 days readmission to YES\n",
    "data['readmitted'] = data['readmitted'].replace(1, 0)\n",
    "data['readmitted'] = data['readmitted'].replace(0, 0)\n",
    "\n",
    "# Select target column to predict\n",
    "X = data.drop(columns=['readmitted'])\n",
    "y = data['readmitted']\n",
    "\n",
    "\n",
    "# Get the unique class names from the target variable\n",
    "class_names = ['YES', 'NO']\n",
    "\n",
    "# Encode strings to unique integers\n",
    "le = LabelEncoder()\n",
    "\n",
    "X_encoded = X\n",
    "y_encoded = y\n",
    "\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4839a9d-03e5-4a82-932a-689739517f11",
   "metadata": {},
   "source": [
    "#### Finding baseline performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e21e2-42e8-4845-932a-dc94cf47b5e5",
   "metadata": {},
   "source": [
    "Next to find the baseline performance of the model we run it without any initalised parameters and use random state 42 to split the dataset into training and testing sets. We also created a function to reduce duplicated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d197102-7ba2-41dd-a496-8df99069334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "ppn = Perceptron()\n",
    "\n",
    "def getAccuracy(ppn):    \n",
    "    print(ppn.get_params())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.25, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    ppn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = ppn.predict(X_test)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    print('\\n Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825a6eb-ebbd-49f0-9f34-c79553841566",
   "metadata": {},
   "source": [
    "After recieving an accuracy score of 0.47, we tried using grid search to find the optimum parameters, however even for a simple model such as perceptron it struggled to finish executing. So we instead wanted to find the top 4 most important parameters to configure and optimised those instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451855e9-af90-4ed0-b6ca-4d7183618fa1",
   "metadata": {},
   "source": [
    "#### Finding the most impactful perceptron hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eaeb54-718f-43b4-9038-1f831d2b52a7",
   "metadata": {},
   "source": [
    "First we listed the available hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0baebf-03cb-4dfc-b476-4d6c862335fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn = Perceptron(\n",
    "    alpha=1.0,\n",
    "    penalty=None,\n",
    "    max_iter=50,\n",
    "    tol=0.0001,\n",
    "    fit_intercept=True,\n",
    "    eta0=0.0001,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight='balanced'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a568aaea-f294-4fee-a12d-bf4a46cd6935",
   "metadata": {},
   "source": [
    "#### Choosing the most impactful parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74353cb6-2aa4-4aca-9c86-90b3d58cf892",
   "metadata": {},
   "source": [
    "##### Finding optimum value for max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757606aa-2e79-45fc-b162-d8e00e7027cb",
   "metadata": {},
   "source": [
    "First we decided that max_iter is the most impactful parameter to the accuracy score, as almost all the other parameters need at least more than 1 iteration to be used. This is because a perceptron works by taking in input values, calculating a weighted sum and then passes them through an activation function to filter them into the classes, the perceptron then adjusts the weights from the previous iteration to improve its accuracy. Without a suitable number of iterations, all the other parameters will be negligable in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a27a5-a007-4496-8c4f-98caca0a6037",
   "metadata": {},
   "source": [
    "Testing max_iter values at 50, 100, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309af6e1-c0d3-48ea-9af5-8e701cd844c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    max_iter=50,\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd7bca2-afad-4f7d-9d50-8b035de06a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 100, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    max_iter=100,\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09344d4a-1cb3-45ba-88d3-c96b869e790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 200, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    max_iter=200,\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba56fcf-8003-4862-858e-684606f8c376",
   "metadata": {},
   "source": [
    "We found that after 50 iterations the model does not improve in accuracy score, so the best parameter for max_iter is 50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b65e3-b6d4-473c-a1d3-953fcad6c38d",
   "metadata": {},
   "source": [
    "##### Finding optimum value for alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c6fce-4bba-4d52-a617-e843ff665c88",
   "metadata": {},
   "source": [
    "Next we decided that alpha is the 2nd most impactful parameter to the accuracy score, as alpha controls the amount of regularisation and can prevent overfitting. Our data is particularly noisy, as it is filled with attributes from human data (weight, age, glucose levels, etc.), meaning there is a lot of variation and randomness, selecting a good alpha score can assist in avoidance of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94da7aba-ef08-441e-be0e-257cbb94bc8e",
   "metadata": {},
   "source": [
    "Testing alpha values at 1e-5, 1e-3, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92244619-129c-48a1-bb16-5e6c09264b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    max_iter=50,\n",
    "    alpha = 1e-5\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da7997e-b58b-4a47-b627-94ed1458c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    max_iter=50,\n",
    "    alpha = 1e-3\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7219bbb-cabc-4829-9b9a-52f2a17f7096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.47\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    max_iter=50,\n",
    "    alpha = 1\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906ab4b-ad93-45e5-b31e-a8fc9dae0121",
   "metadata": {},
   "source": [
    "There was no difference when changing the alpha value, as the accuracy remained at 0.47. We opted to choose the middle value, 1e-3 to avoid overfitting and underfitting of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86060d8-925f-4f37-b19c-5f3db41ce020",
   "metadata": {},
   "source": [
    "##### Finding optimum value for shuffle and class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972af25f-fb76-474b-a12f-aca7fa14dfc3",
   "metadata": {},
   "source": [
    "It seemed that the default parameter values for max_iter, alpha and tol were enough to reach the peak accuracy score of 0.47. So next, we wanted to try turning off shuffle so the model can find patterns within the data better and reach a higher accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f58796b-2f20-4a67-8ded-ba8c0a046759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    alpha=1e-3,\n",
    "    max_iter=50,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479dca99-3ab1-4074-a457-092eae43571e",
   "metadata": {},
   "source": [
    "This gained us a little boost in accuracy of 0.01, at the cost of the model potentially being too biased to the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa6b9c-9a77-4773-9d87-324ce6c6a076",
   "metadata": {},
   "source": [
    "##### Finding optimum value for class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41897eb3-3129-4add-9f05-b75cbd4d064f",
   "metadata": {},
   "source": [
    "We noticed the data was quite unbalanced with 52833 values of patients who do have not been readmitted, with only 45595 patients who have been readmitted, making a difference of 7238. So we wanted to try and change the value of the class_weight parameter to balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf162ca-7d36-4e1e-b25f-0fb4bbaf578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readmitted\n",
      "2    52833\n",
      "0    45595\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['readmitted'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ceab629-97a6-437f-90f0-cbf71f85a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    alpha=1e-3,\n",
    "    max_iter=50,\n",
    "    shuffle=False,\n",
    "    class_weight=None\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9005604-9255-42ef-afdb-5ebfa5111f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'class_weight': 'balanced', 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 50, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': False, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(\n",
    "    alpha=1e-3,\n",
    "    max_iter=50,\n",
    "    shuffle=False,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "getAccuracy(ppn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858dbdf-21f6-47f0-91ab-59e544a7cfc5",
   "metadata": {},
   "source": [
    "After doing so we reached the highest score for this model at 0.58, however this is with shuffle set to false, for a robust model it would be much more preferable to have shuffle on, so that the model can handle randomness in real input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7517b1-d894-40bd-ab59-38eae4db8060",
   "metadata": {},
   "source": [
    "#### Scaling data for improved performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01bf0b-d2ae-488f-9b01-88ba8141204c",
   "metadata": {},
   "source": [
    "We set shuffle to True, to improve robustness, and then scaled the data to assist in perceptron performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e92d58b-ba37-4e65-b542-cb4bcbb63ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'class_weight': 'balanced', 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      " Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "ppn = Perceptron(\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    shuffle=True,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "print(ppn.get_params())\n",
    "\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "ppn.fit(X_train_std, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print('\\n Accuracy: %.2f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582d2b1-3773-47e5-8d2d-0f953ac39ebf",
   "metadata": {},
   "source": [
    "We achieved a score of 0.55 which is the best score we could achieve while keeping shuffle set to True."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
